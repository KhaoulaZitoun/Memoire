\chapter*{Conclusion}
\addcontentsline{toc}{chapter}{Conclusion}
\markboth{Conclusion}{Conclusion}
\label{chap:conclusion}



Dans ce mémoire nous nous sommes intéressés aux phases d'étude et de recette du cycle en V et de la méthode agile. Nous avons considéré que l'automatisation des tests d'acceptation à partir des exigences devait permettre à toutes les parties prenante de lire et/ou écrire les exigences, de générer automatiquement des tests fonctionnels et d'avoir un retour des tests au niveau des exigences. Nous avons montré que l'ingénierie des exigences pouvait être une piste intéressante pour répondre à notre problématique.

Nous avons d'abord présenté des outils qui permettaient de passer des exigences aux tests fonctionnels. Ceux-ci ne répondaient pas au critère d'automatisation. Nous avons ensuite, dans le cadre de l'ingénierie des exigences, proposé de modéliser les exigences dans un premier temps pour ensuite générer des tests fonctionnels à partir de cette modélisation. Des modélisations structurelles, comportementales ou encore des méthodes formelles ont été présentées. Ces modélisations étaient soit trop techniques, ou ne présentaient pas assez de détails ou encore ne permettaient pas de générer des tests. Toutefois, nous avons vu que les Domain Specific Language permettaient de réunir bon nombre de nos critères notamment le critère d'impliquer le domaine métier au coeur de la modélisation, de proposer une simplicité d'écriture et de lecture pour toutes les parties prenantes et surtout la génération des tests fonctionnels. Par conséquent, nous nous sommes tournés vers les outils orientés Behaviour Driven Developement tel que Cucumber qui propose un DSL représentant des scénarios à partir desquels des signatures de méthodes de tests fonctionnels sont générés. Néanmoins, ce genre d'outils ne permettant pas d'avoir un retour clair au niveau des exigences du résultat des tests, nous avons souhaité proposer notre propre solution.

Pour tenter de répondre à tous les critères que nous avions établi, nous avons proposer de mettre en place un outil basé sur un DSL pour représenter les exigences à partir duquel les tests d'acceptation seraient générés grâce à des mots clé définis. Une fois ces tests implantés par les développeurs, à chaque fois qu'ils sont testés, des commentaires qui décrivent le résultat de chaque test sont rédigés dans le code. Les commentaires sont ensuite analysés : si le test est passé un élément graphique coloré, défini dans le DSL s'affichera près de chaque mot clé pour signifier le résultat du test. Ainsi, quelque soit la partie prenante, il est possible de savoir quelle exigence a été respectée ou non en un coup d'oeil.
Cependant notre solution présente des failles, notamment de qualité, car les développeurs peuvent influencer manuellement le résultat des tests. 
Il serait intéressant, après avoir pallié à ces failles, d'étendre cette solution à d'autres types de tests tels que des test non-fonctionnels ou de contrainte par exemple.